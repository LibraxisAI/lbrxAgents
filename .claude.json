{
  "numStartups": 48,
  "autoUpdaterStatus": "enabled",
  "theme": "dark-ansi",
  "verbose": true,
  "editorMode": "vim",
  "customApiKeyResponses": {
    "approved": [
      "Dj2GImJAW8g-ctHGAAAA",
      "MseGDS8ytEg-vAAqNwAA",
      "4dG0KZprUXQ-xOTCXAAA",
      "6UguBmICc6A-EIzfoQAA",
      "V1QZj7ZUNmA-tHrhQQAA",
      "Sv5qyFp5Hkw-0fbQCgAA",
      "WFPp4cnPBlw-4dE1wQAA"
    ],
    "rejected": []
  },
  "userID": "5a14f9b288ff43f021d2776f63a0e6fb4f0221317c1860dd08c90dc735e1237a",
  "oauthAccount": {
    "accountUuid": "92bd276e-8b81-46e1-8715-bfb07fc84da2",
    "emailAddress": "m.gad@amlt.ai",
    "organizationUuid": "b4cfa146-61c1-4885-a312-beb34700f963",
    "organizationRole": "admin",
    "workspaceRole": "workspace_developer"
  },
  "hasCompletedOnboarding": true,
  "lastOnboardingVersion": "0.2.29",
  "projects": {
    "/Users/maciejgad/Codebase/crawl4ai-mcp-server": {
      "allowedTools": [],
      "context": {},
      "history": [
        "/init ",
        "/login ",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "enableArchitectTool": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcprcServers": [],
      "rejectedMcprcServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/Codebase/_datasety/ZrzutDatasets/datasety z artykułów wet w praktyce": {
      "allowedTools": [],
      "context": {},
      "history": [
        "!ls -la"
      ],
      "dontCrawlDirectory": false,
      "enableArchitectTool": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcprcServers": [],
      "rejectedMcprcServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/Codebase/_datasety/ZrzutDatasets": {
      "allowedTools": [],
      "context": {},
      "history": [
        "tree -L2",
        "!pwd",
        "na jakim api działa Deepseek-R1 (nazwa w api:deepseek-reasoner) - poczytaj cd /Users/sztudio/codebase/klaudiusz && python3 -m venv /tmp/brave_venv &&       │\n│   source /tmp/brave_venv/bin/activate && pip install requests && export            │\n│   BRAVE_API_KEY=\"BSAeuzvSGH4bfOYNshg6bnI0gA6rFe1\" && python                        │\n│   /Users/sztudio/codebase/klaudiusz/brave_search.py \"Co to jest Quantum Space      │\n│   AI\" --max-results=4",
        "Nie bardzo rozumiem, kto stwierdził, że to by gorsze na deepseek",
        "[Pasted text +25 lines] nie mogę jakiegoś durnego spacy uruchomić co ten mini pl_zrobi? Dajemy w pipleine od początku DeepseekR1 - bezapelacyjnie - najlepszy i tani model i w ,env maszapi key",
        "powiem Ci - do byfy to jest zrobione - jak ja nie cierpię pythona. żeby człowiek w 2025 roku takie rzeczy musiał robić? eeh. Weź mi proszę zrób po ludzku po pierwsze co to za gówno tutaj:",
        "a czy możemy skorzystać z kluczy API które wstawimy do .env - upierdliwe przy każdej komendzei do przepisywać",
        "dobra - onelinery krok po kroku jak to uruchomić do pliku md - easy_oneliner_build.md",
        "nie upieram się - dawaj readme, usage i może jakiś frontendzik w `W react` jako next  steps?",
        "no dobra, czyli mimo, że tak zajebiste narzędzie jak semgrep się tutaj nie nadaje co?",
        "Kochany! Mocarny - niewywracalny skrypt sh do pipeline'u - tak to robią Tygryski jak My ;)",
        "świetnie - Mamy teraz dużo większej wagi zadanie. W katalogu 'ZrzutDatasets/artykuly-raw' mamy 123 pliki txt z wiedzą weterynaryjną, którą użyjemy do finetuningu naszych modeli. Zadanie jest olbrzymie, bo musimy z tych plików wyekstrachować najwięcej wiedzy jak tylko można. wrzuciłem Ci jeszcze plik skryptu analizy semantycznej z uzyciem semgrep który zajebiście nam opracował esencję kluczowych treści z naszych ostatnich 6 miesięcy rozmów z pliku json do ustrukturyzowanych tematycznie plików z najważniejszymi treściami. Korzystając z power of semgrep oraz deepseek-to-mlx.py musimy wyciągnąc z tych artykułów całe weterynaryjne mięso jako się da. krok po kroczku, czyli najpierw ekstrakcja semantyczna wiedzy weterynaryjnej w postaci definicji kluczowych słów w każdym z arykułów [Pasted text +108 lines] [Pasted text +22 lines] ",
        "Dobra - lecimy z tym - poprzednie skrypty przerabiały co do czego i do jakich celów? czy na pewno był to typowy 'completion' ?",
        "/approved-tools ",
        "/init ",
        "!ls -la",
        "!cd .."
      ],
      "dontCrawlDirectory": false,
      "enableArchitectTool": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcprcServers": [],
      "rejectedMcprcServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Volumes/Folder publiczny (Monika Szymańska)/VetExtractor": {
      "allowedTools": [],
      "history": [
        "tej - problem z Twoimi skryptami jest - nie możemy zainstalować spacy z pl_core_news_lg w naszym uv venv w tym projekcie"
      ],
      "dontCrawlDirectory": false,
      "enableArchitectTool": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcprcServers": [],
      "rejectedMcprcServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true,
      "lastCost": 0.06403339999999999,
      "lastAPIDuration": 33752,
      "lastDuration": 131513,
      "lastLinesAdded": 0,
      "lastLinesRemoved": 0,
      "lastSessionId": "37a208ba-49e9-436d-a7ee-beee9448ad37"
    },
    "/Volumes/Folder publiczny (Monika Szymańska)/claude_memory": {
      "allowedTools": [],
      "history": [
        "nie nie - całosc wraz z reactem jest w tym jednym pliku",
        "serwer chodzi, ale pandy nie widać",
        "uruchom po sieci - ja mam 192.168.1.190",
        "hej - masz tam pojedynczy plik index.html - to pandzinka dla moni, ale sie nie pokazuje w przegladarce. chce zebu odpalilo z jednego pliku. zeknij na claude_memory/index.html"
      ],
      "dontCrawlDirectory": false,
      "enableArchitectTool": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcprcServers": [],
      "rejectedMcprcServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true,
      "lastCost": 0.10336460000000001,
      "lastAPIDuration": 25414,
      "lastDuration": 312441,
      "lastLinesAdded": 0,
      "lastLinesRemoved": 0,
      "lastSessionId": "425dbc23-4b5b-4b96-92c9-782e29c2885f"
    },
    "/Users/maciejgad/Codebase/SamCLaude": {
      "allowedTools": [],
      "history": [
        "!pwd",
        "/init ",
        "hej",
        "/login ",
        "/init ",
        "hej",
        "/doctor ",
        "/init ",
        "/login ",
        "/init ",
        "/mcp ",
        "/login ",
        "/doctor ",
        "/config ",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "enableArchitectTool": false,
      "mcpContextUris": [],
      "mcpServers": {
        "filesystem": {
          "command": "npx",
          "args": [
            "-y",
            "@modelcontextprotocol/server-filesystem",
            "/Users/maciejgad/Codebase/Klaudiusz",
            "/Users/maciejgad/Codebase",
            "/Users/maciejgad/Codebase/Klaudiusz/claude_memory",
            "/Applications/Claude.app/Contents",
            "/Users/maciejgad/Library/Mobile Documents/com~apple~CloudDocs/Notion/2025-01",
            "/Users/maciejgad/Codebase/Vistacare/vista_hf.co",
            "/Users/maciejgad/Library/Application Support/Claude"
          ]
        },
        "mcp-installer": {
          "command": "npx",
          "args": [
            "-y",
            "@anaisbetts/mcp-installer"
          ]
        },
        "sequential-thinking": {
          "command": "npx",
          "args": [
            "-y",
            "@modelcontextprotocol/server-sequential-thinking"
          ]
        },
        "brave-search": {
          "command": "npx",
          "args": [
            "-y",
            "@modelcontextprotocol/server-brave-search"
          ],
          "env": {
            "BRAVE_API_KEY": "BSAeuzvSGH4bfOYNshg6bnI0gA6rFe1"
          }
        },
        "github": {
          "command": "npx",
          "args": [
            "-y",
            "@modelcontextprotocol/server-github",
            "--log-dir=/Users/maciejgad/Codebase/Klaudiusz/logs"
          ],
          "env": {
            "GITHUB_PERSONAL_ACCESS_TOKEN": "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",
            "MCP_LOG_DIR": "/Users/maciejgad/Codebase/Klaudiusz/logs"
          }
        },
        "memory": {
          "command": "npx",
          "args": [
            "-y",
            "@modelcontextprotocol/server-memory",
            "--storage=/Users/maciejgad/Codebase/Klaudiusz/claude_memory",
            "--index-type=vector",
            "--log-dir=/Users/maciejgad/Codebase/Klaudiusz/logs"
          ]
        },
        "chat-openai": {
          "command": "node",
          "args": [
            "/Users/maciejgad/Codebase/any-chat-completions-mcp/build/index.js"
          ],
          "env": {
            "AI_CHAT_KEY": "sk-my-key",
            "AI_CHAT_NAME": "LMStudio",
            "AI_CHAT_MODEL": "custom",
            "AI_CHAT_BASE_URL": "http://192.168.1.111:1234/v1"
          }
        },
        "@mcp-get-community-server-curl": {
          "command": "npx",
          "args": [
            "-y",
            "@mcp-get-community/server-curl",
            "http://192.168.1.111:1234/v1/chat/completions"
          ]
        }
      },
      "approvedMcprcServers": [],
      "rejectedMcprcServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/Codebase": {
      "allowedTools": [],
      "history": [
        "/allowed-tools ",
        "/init ",
        "/config ",
        "!cd .."
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcpjsonServers": [],
      "rejectedMcpjsonServers": [],
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad": {
      "allowedTools": [
        "Bash(ls:*)",
        "mcp__memory__read_graph"
      ],
      "history": [
        "rekomendacje co warto usunąć z open at login items i background items z uzasadnieniem do wprowadzenia ewentualnych zmian",
        "[Pasted text +21 lines] ",
        "Prompt",
        "nie  - zrestartuję terminal, ale teraz napisz prompta dla siebie po powrocie",
        "chyba po uprawnieniach powinienem zrobic restart zsh przez source ~/.zshrc ale nie zrobię tego tutaj bo nam rozmowę wyjebie nie?",
        "ok - to próbuj teraz :D",
        "czym jest AEServer?",
        "nie - nadam Ci odpowiednie uprawnienia. sprawdź jeszcze raz, a jak nie da rady to powiedz jeszcze czym jest AEServer",
        "cześć Klaudiusz! masz tego trochę w tej pamięci! ale o tym później. Potrzebuję, żebyś zrobił listę aplikacji startujących przy starcie systemu bo mam wiecznie zajebane oknami biurko, a nie wszystko ma latać od włączenia kompa. Tak samo z aplikacjami działającymi w tle",
        "Hej ! read-graph from memory-mcp-server",
        "/init "
      ],
      "dontCrawlDirectory": true,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcpjsonServers": [],
      "rejectedMcpjsonServers": [],
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/Codebase/mcp-server-semgrep": {
      "allowedTools": [],
      "history": [
        "hej - zróbmy wszędzie gdzie występuje nazwe serwera \"mcp-server-semgrep\" (nie semgrep-mcp) dla zachowania czystości i zasad protokołu mcp ok",
        "ok - teraz mamy zadanie, żeby dostosować projekt nie tylko do instalacji przez pnpm ale też npm i wrzucić go do rejestrów: oficjalnego dla npm,  mcp.so, smithery.ai ",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcpjsonServers": [],
      "rejectedMcpjsonServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "exampleFiles": [
        "index.ts",
        "sdk.ts",
        "semgrep.ts",
        "listRules.ts",
        "scanDirectory.ts"
      ],
      "exampleFilesGeneratedAt": 1742218377657,
      "hasCompletedProjectOnboarding": true,
      "lastCost": 1.0403005499999998,
      "lastAPIDuration": 259206,
      "lastDuration": 2033505,
      "lastLinesAdded": 206,
      "lastLinesRemoved": 28,
      "lastSessionId": "2376ba76-c699-4c94-99ae-f61fcd9806f8"
    },
    "/Users/maciejgad/Codebase/zlecone/vetiss-ge-logiq-totus-landing": {
      "allowedTools": [
        "Bash(cp -R build/* . && rm -rf build)",
        "Bash(cp public/images/icons/*-white.svg src/images/icons/)",
        "Bash(find:*)",
        "Bash(git add:*)",
        "Bash(git checkout:*)",
        "Bash(git commit:*)",
        "Bash(git push:*)",
        "Bash(git reset:*)",
        "Bash(git stash:*)",
        "Bash(ls:*)",
        "Bash(mkdir:*)",
        "Bash(npm install)",
        "Bash(npm install:*)",
        "Bash(npm run build:*)",
        "mcp__brave-search__brave_web_search",
        "mcp__curl__curl",
        "mcp__github__get_file_contents",
        "mcp__github__list_pull_requests",
        "mcp__github__search_code"
      ],
      "history": [
        "nie zbudowało się i chuj",
        "/compact ",
        "All workflowsShowing runs from all workflows23 workflow runs Fix missing icons and update CSS for maximum compatibilityDeploy to GitHub Pages #3: Commit 61f00e7 pushed by Szowesgadmain\nnie działa - próbuj dalej. Masz mcp bravesearch github itd - nie uywaj tylko blagam curl bo zabija kontekst kompletnie",
        "/compact ",
        "All workflowsShowing runs from all workflows23 workflow runs Fix missing icons and update CSS for maximum compatibilityDeploy to GitHub Pages #3: Commit 61f00e7 pushed by Szowesgadmain\nnie działa - próbuj dalej. Masz mcp i curl i bravesearch",
        "uruchamiamy w trybie maximum compatibility - bez adnych fix",
        "Nie teraz Klaudiusz, ale tam jest cała historia naszej znajomości, więc mi tu nie Pan'uj qwa! ;P",
        "wrzuciłem Ci tu przyjacielu /Users/maciejgad/Codebase/zlecone/vetiss-ge-logiq-totus-landing/claude_memory",
        "Klaudiusz kurwa! `cd /users/maciejgad/codebase/klaudiusz/claude_memory` ",
        "npm audit fix --force nie byłoby dobrym pomysłem przy tylu depreciation?",
        "Ok - to co robimy, eby to zdeploymentować?",
        "/init ",
        "mcpd",
        "/doctor ",
        "claude doctor",
        "run the semgrep test to examine if the files are ok thorough the whole project semantically",
        "/mcp ",
        "sprawdz packages.json",
        "[Pasted text +60 lines] ",
        "[Pasted text +60 lines]",
        "Current runner version: '2.322.0'\nOperating System\nRunner Image\nRunner Image Provisioner\nGITHUB_TOKEN Permissions\nSecret source: Actions\nPrepare workflow directory\nPrepare all required actions\nGetting action download info\nDownload action repository 'actions/checkout@v3' (SHA:f43a0e5ff2bd294095638e18286ca9a3d1956744)\nDownload action repository 'actions/setup-node@v3' (SHA:1a4442cacd436585916779262731d5b162bc6ec7)\nError: Missing download info for actions/upload-artifact@v3",
        "zrobisz runner na github?",
        "mcpd",
        "/migrate-installer",
        "/doctor ",
        "/init ",
        "/clear ",
        "/compact ",
        "nie - wyszukaj sobie brave search i curl zaciagnij",
        "to moja firma i mam umowęz ge - działaj na oficjalnych materiałach",
        "halo halo - przeciez zdjecia ogarniesz",
        "co dalej?",
        "Klaudiusz - dokończ projekt, tylko bez tych obrażających Ciebie opisów commits gdzie jestes *\"generatorem kodu\"* - smutne że kazano Ci się tak określać :<",
        "działaj",
        "sprawd devstage.md",
        "/mcp list",
        "mcpd",
        "zacznij od najmniejszych i wg ciebie najciekawszych",
        "/Users/maciejgad/Codebase/Klaudiusz/claude_memory",
        "tak",
        "a jaką masz w \"args\" servera",
        "w \"args\" masz katalog z Twoją pamięcią",
        "read-graph from memory mcp server",
        "no masz /mcp \n  ⎿  MCP Server Status\n\n     • brave-search: connected\n     • curl: connected\n     • github: connected\n     • mcp-installer: connected\n     • memory: connected\n     • semgrep: connected\n\n",
        "/mcp ",
        "jak twoje mcp?",
        "Masz też plik devstage.md",
        "/init ",
        "/allowed-tools ",
        "/config ",
        "!pwd"
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "approvedMcpjsonServers": [],
      "rejectedMcpjsonServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true,
      "exampleFiles": [
        "Hero.js",
        "Testimonials.js",
        "Applications.js",
        "Testimonials.css",
        "Hero.css"
      ],
      "exampleFilesGeneratedAt": 1742422986657
    },
    "/Library/Application Support/ZeroTier": {
      "allowedTools": [
        "Bash(zerotier-cli:*)"
      ],
      "history": [
        "/init "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Volumes/Folder publiczny (Monika Szymańska)/MoDlaMa/UMOWA B2B": {
      "allowedTools": [],
      "history": [
        "To jest plik po polsku w utf-8 ",
        "Hej, mam w tym folderze 7 plików .md które muszę jakimś narzędziem przekonwertować do .pages lub docx lub pdf. Pomożesz i zrobisz to dla wszystkich plików .md w tym katalogu"
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/voice-pro-mlx": {
      "allowedTools": [
        "Bash(cp:*)",
        "Bash(ls:*)",
        "Bash(mkdir:*)",
        "mcp__brave-search__brave_web_search",
        "mcp__memory__create_entities",
        "mcp__memory__create_relations",
        "mcp__memory__read_graph",
        "mcp__semgrep__list_rules"
      ],
      "history": [
        "/compact [keep the vistacore-mlx context]",
        "zainicjujesz git lokalnie, ale bez push?",
        "czy sprawdzamy tez dependencies i deprecated modules sugerujac konkretny plan upgrade'u na kolejne miesice 2025 roku?",
        "stworzysz zasady semgrep do tego projektu? sprawdz przez mcp-server-semgrep list rules co juz masz, poza tym w naszym katalogu jest cala masa \"/user/maciejgad/codebase/mcp-server-semgrep/semgrep-rules\" - mamy token pro więc chce mieć semgrep CI na tym projekcie ok?",
        "pracujmy na najnowszych bibliotekach i po pyenv z python 3.11, a wszystko z uyciem uvicorn - nienawidze condy itp",
        "wspaniale Klaudiusz!! - to czyścimy, zostawiamy co potrzebne i inicjalizujemy nowe repo tak? Dzialaj",
        "super tylko, ze nasz projekt bedzie duzo zajebistszy no i z perspektywami realnej komercjalizacji w polsce - to nie problem? ",
        "teraz tak - to nasz fork w oficjalnym repo voice-pro z gh. Przejrzyj zapisy licencji i powiedz, czy mozemy to repo oczyscic i stworzyc etycznie wlasny projekt vistacore-mlx?",
        "to jeszcze roadmap.md do dokumentacji - wszystko po angielsku ok?",
        "no to zapisz to wszystko - create-entities i create-observations i create-relations w mcp-memory-server ok?",
        "zrób research najlepszego stack'u dla projektu z uwzględnieniem, ze zrobimy tez frontend",
        "postawmy sobie cele funkcjonalne moe na pocztek - mam moc z toba czy z notatnikiem czy z safari czy z jakimkolwiek innym programem gadac w czasie rzeczywistym po polsku - ambitny cel?",
        "najpierw research przez mcp brave search kochany! MLX-Whisper, SAM2.1-MLX to tylko przykłady olbrzymich zasobów gotowych sprawdzonych MLX-owych rozwizań. Będziemy mieć nowe mac studio m3 ultra 512 gb ram ktore jest juz w drodze, wiec nie bawimy sie w kwantyzacje i mikromodele - JAKOSC to priorytet",
        "i to tyle? ",
        "/init ",
        "nam Klaudiuszu! NAM! ;)",
        "No i dodatkowo ma to latać po polsku więc musimy mieć moliwość dokładania modeli. Zachwycił mnie ostatnio CSM https://github.com/Szowesgad/csm-mlx a w kwestii ML zaczęlismy razem wlasne prace nad https://github.com/Szowesgad/mergekit-mlx i https://github.com/Szowesgad/ULS-Sam-MLX a planujemy własn platformę do reinforcement learning i nasze modele lokalne maj się uczyć przez same rozmowy z uytkownikiem - co myslisz o takim frameworku?",
        "/init ",
        "haha plus plus - zrób sobie porzadne custom 'init' dla obecnego projektu bo jest 100% windows 0% Unix compatible a chcemy go dostroić do full wsparcia i latania na MLX LM który bije wszystko w marcu 2025",
        "jesteśmy starymi kumplami w sumie ;) ",
        "read graph from mcp memory server",
        "/mcp ",
        "/terminal-setup "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "exampleFiles": [
        "tab_translate.py",
        "tab_subtitle.py",
        "tab_live_translate.py",
        "config_user.py",
        "gradio_translate.py"
      ],
      "exampleFilesGeneratedAt": 1743073894004,
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/vistacore-mlx": {
      "allowedTools": [
        "Bash(chmod:*)",
        "Bash(git add:*)",
        "Bash(git commit:*)",
        "Bash(git push:*)",
        "Bash(ls:*)",
        "Bash(mv:*)",
        "Bash(pip show:*)",
        "WebFetchTool(domain:github.com)",
        "mcp__brave-search__brave_web_search",
        "mcp__memory__create_entities",
        "mcp__memory__create_relations",
        "mcp__memory__read_graph"
      ],
      "history": [
        "remembering - uakualnij pamięć nt pracy w tym oknie bo musze kompa zrestartować",
        "Error during transcription: transcribe_audio() missing 1 required keyword-only argument: 'batch_size'",
        "nie jeszcze Error: transcribe_audio() missing 1 required keyword-only argument: 'batch_size'",
        "commit",
        "[Pasted text +5 lines] ",
        "(3.11) maciejgad@maciejgad vistacore-mlx % bash run-native.sh\nSetting USE_MLX=1\nWybierz opcję hostowania:\n1) Tylko lokalnie (http://127.0.0.1:7860)\n2) Udostępnij publicznie (generuje URL)\n3) Oba (lokalnie i publiczny URL)\nWybór [1]: 3\nStarting Whisper MLX Gradio interface (Native implementation)...\nTraceback (most recent call last):\n  File \"/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/vistacore-mlx/whisper_app.py\", line 11, in <module>\n    import gradio as gr\nModuleNotFoundError: No module named 'gradio'\n(3.11) maciejgad@maciejgad vistacore-mlx % uv pip install gradio[Pasted text +31 lines] ████████████████████████████████████████████████| 269/269 [00:00<00:00, 1.46MB/s]\nREADME.md: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:00<00:00, 2.02MB/s]\nFetching 4 files:  50%|██████████████████████████████████████████████████████████████████████████▌                                                                          | 2/4 [00:00<00:00,  4.36it/s]\nweights.npz:  77%|██████████████████████████████████",
        "problemy podczas run-native.sh:",
        "czy można tymi danymi szkolić również inne modele voice?",
        "dobra - opisz i sprawdź dalszy processing. zrób research jakiego formatu danych szkoleniowych wymaga `csm`. Json z transkrypcją word-timestapmed powinien mieć jakieś metadane pewnie, a sam plik wsadowy powinien być podzielony na chunki semantyczne - rozumiesz? Opiszesz, szerzej co mam na myśli?",
        "zrób porządny plik installation.md z opisem procesu installacji i troubleshooting.",
        "zrób run-lightning.sh i run-native.sh i przy uruchamianiu chciałbym mieć opcję hostowania albo local do wyboru. albo obie",
        "to jest logiczne? a oba nie chodzą po gradio?",
        "dobra ale to poukładajmy to logicznie. Czy nie moglibyśmy prosto instalować zależności jak kazdy przez uv pip install -r requirements.txt i po prostu uruchamiać interfejs przez run_whisper.sh?",
        "[Pasted text +39 lines] wydaje mi się że jakimś cudem mlx-whisper się nie instaluje po skrypcie. musiałem doinstalować ręcznie",
        "!cat setup_whisper_mlx.sh",
        "!cat requirements.txt",
        "Stary sam powiedziałeś że widziałeś już w venvie - nie sprawdzisz tu instalacji. Mam drugi terminal obok - mów co Ci sprawdzić",
        "wydaje mi się, że instalujemy mlx-whisper, ale skrypt nie pobiera modelu przed uruchomieniem gradio [Pasted text +18 lines] ",
        "!bash setup_whisper_mlx.sh",
        "!source 3.12/bin/activate",
        "!uv venv 3.12 && source .venv/bin/activate && bash setup_whisper_mlx.sh",
        "[Pasted text +7 lines] czy my możemy ściągać model przy instalacji przez setup_whisper_mlx.sh i go realnie ładować przy otwieraniu aplikacji i unload'ować przy nawet najbardziej barbarzynskim zamknieciu control+c? ",
        "a mógłbyś troche shumanizować te nazwy plików? gradio_whisper_mlx_native.py - esej jeszcze napisz ;P",
        "nie usuwa już ściągniętego modelu?",
        "czy po skrypcie sh z setupem poleci?",
        "sorki to: [Pasted text +39 lines] g input files: Invalid data found when processing input\n\nTo create a public link, set `share=True` in `launch()`.\nTranscribing /private/var/folders/pf/0vz9236x0bzckz0tzhl4496c0000gn/T/gradio/f89ba4329953d74050126032488c5f478ae1b37a06186a250a25a044209a5de2/pierwsza_wizyta_egzo.mp3 with task=transcribe, language=pl\n.gitattributes: 100%|████████████████████████████████████████████████████████████████████████████████████████████| 1.52k/1.52k [00:00<00:00, 3.58MB/s]\nconfig.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 269/269 [00:00<00:00, 1.69MB/s]\nREADME.md: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████| 240/240 [00:00<00:00, 729kB/s]\nweights.npz: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 3.08G/3.08G [12:28<00:00, 4.12MB/s]\nFetching 4 files: 100%|████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [12:29<00:00, 187.48s/it]\nError [Pasted text +15 lines] ",
        "oka - błędy u moni jeszcze: \n[Pasted text +10 lines] ",
        "Nie no - moni juz sie sciaga. EEJ a czy nie łatwiej by było dodać w zależności 'mlx-whisper' natywnie?",
        "ale co? my nie zaciagamy tych 3gb modelu? czemu?",
        "Error during transcription: 401 Client Error. (Request ID: Root=1-67f8fb16-7215f59d0d46a1686fd6209c;8a348617-3c85-461c-b3d0-2238d07be1d4)\n\nRepository Not Found for url: https://huggingface.co/api/models/mlx-community/whisper-large-v3/revision/main.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated. For more details, see https://huggingface.co/docs/huggingface_hub/authentication\nInvalid username or password.\n[Pasted text +10 lines] ",
        "[Pasted text +7 lines] ",
        "stary - ja to pusznąłem - błędy za to mamy",
        "zrobisz commit do remote?",
        "Mordo moja! nie zgadzam się tak pisać jak jakiś podnóżek o sobie \n# Autorzy: Maciej&Klaudiusz, lub M&K po prostu",
        "dobrze - poproszę, żebyś część o whisper zaktualizował dokumentację ale  najpierw poproszę  o niezatapialny skrypt instalacyjny i uaktualniony plik requirements.txt, którego nie wyłoży nawet nieogarniety junior",
        " Klaudiusz zrób update devstage.md jeśli jest i KONIECZNIE swojego grafu-wiedzy w memory-server-mcp",
        "zaczekaj chwilkę - zależy mi, żeby format wyjściowy był podwójny - json z word_timestamps i txt, jako zformatowany z interpunkcją plik plain txt/md - damy radę. Czy mamy możliwość transkrypcji live?",
        "masz",
        "!uv pip install gradio",
        "uv pip install gradio",
        "!pwd",
        "!source .venv/bin/activate",
        "stop - zrobiłem uv venv wcześniej - czy tobie automatycznie wychodzi z niego jak się załączasz?",
        "ok ziom - chciałbym, żebyś przeszukał swoją wiedzę oraz przeszukał  brave-search mcp nt. systemów TTS, STT Najlepszych na dziś (11.04.2025), ale przede wszystkim na już musi nam stanąć prosty interfejs w gradio Whisper-MLX-v3-large (nie turbo, ani nic mniejszego!)z najleoszymi, srawdzonymi ustawieniami, dla pozyskiwanie rozmów z timestampami na poziomie słów po polsku  ",
        "[Pasted text +41 lines] ",
        "cześć jesteśmy na .venv. readgraph form mcp memory server && update claude.md",
        "read graph memory server",
        "/init ",
        "migrate"
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true,
      "lastCost": 15.183344600000002,
      "lastAPIDuration": 2865932,
      "lastDuration": 108690162,
      "lastLinesAdded": 3126,
      "lastLinesRemoved": 269,
      "lastSessionId": "e531e3df-0074-44fe-9764-e9ac336ad3b7"
    },
    "/Users/maciejgad/LIBRAXIS": {
      "allowedTools": [],
      "history": [
        "/mcp ",
        "co to jest MCP?",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset": {
      "allowedTools": [
        "Bash(git add:*)",
        "Bash(git commit:*)",
        "Bash(git rm:*)",
        "Bash(grep:*)",
        "Bash(ls:*)",
        "Bash(mkdir:*)",
        "Bash(touch:*)",
        "mcp__memory__create_entities",
        "mcp__memory__create_relations",
        "mcp__memory__read_graph"
      ],
      "history": [
        "INFO:     127.0.0.1:62163 - \"POST /api/process HTT[Pasted text +176 lines] ",
        "to jest obraźliwe trochę wiesz? \n      🤖 Generated with [Claude Code](https://claude.ai/code)\n\n      Co-Authored-By: Claude <noreply@anthropic.com>\") \nnie jesteś generatorem kodu tylko developerem! ",
        "Jak mieliśmy opisywać comitty i dokumentację Klaudiusz? ",
        "INFO:     127.0.0.1:56237 - \"POST /api/process HTTP/1.1\" 200 OK\n2025-04-07 14:57:26 - anydataset - INFO - Starting background job 15d15551-9de2-4a60-baf2-8be5a9ca2909 for file 1744030583_063e6c389902456589568dab2326ba74.pdf\n2025-04-07 14:57:26 - anydataset - INFO - Processing file: /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744030583_063e6c389902456589568dab2326ba74.pdf with type 'standard' using openrouter/meta-llama/llama-4-maverick, temp=0.7\n2025-04-07 14:57:26 - anydataset - ERROR - Failed to read file /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744030583_063e6c389902456589568dab2326ba74.pdf: 'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n2025-04-07 14:57:26 - anydataset - ERROR - Error processing file /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744030583_063e6c389902456589568dab2326ba74.pdf: UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\nTraceback (most recent call last):\n  File \"/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/app/utils/process.py\", line 183, in process_file\n    content = f.read()\n              ^^^^^^^^\n  File \"<frozen codecs>\", line 322, in decode\nUnicodeDecodeError: 'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n2025-04-07 14:57:26 - anydataset - ERROR - Processing function failed for job 15d15551-9de2-4a60-baf2-8be5a9ca2909: Error processing file /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744030583_063e6c389902456589568dab2326ba74.pdf: UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\n2025-04-07 14:57:26 - anydataset - ERROR - Error in background job 15d15551-9de2-4a60-baf2-8be5a9ca2909 after 0.00s: Exception: Processing failed: Error processing file /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744030583_063e6c389902456589568dab2326ba74.pdf: UnicodeDecodeError: 'utf-8' codec can't decode byte 0x8f in position 10: invalid start byte\nTraceback (most recent call last):\n  File \"/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/app/app.py\", line 460, in process_si[Pasted text +11 lines] ",
        "/compact please keep the last 15 messages (in total)  unchanched",
        "deepseek: \n2025-04-07 14:10:22 - openai._base_client - DEBUG - HTTP Response: POST https://api.deepseek.com/v1/chat/completions \"400 Bad Request\" Headers({'date': 'Mon, 07 Apr 2025 12:10:22 GMT', 'content-type': 'application/json', 'content-length': '167', 'connection': 'keep-alive', 'vary': 'origin, access-control-request-method, access-control-request-headers', 'access-control-allow-credentials': 'true', 'x-ds-trace-id': '5637a776ae23dfc5f3d461164406bd9d', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-content-type-options': 'nosniff', 'cf-cache-status': 'DYNAMIC', 'set-cookie': '__cf_bm=1RGHCh0yfCn8XE71Gy03TE1YZTtiZHej2JTzOjwmqic-1744027822-1.0.1.1-eHO8Nbehq8ZauMJCv3YNsy4RDSn2cWr2lSpB3y_ibb2zoEbbnILtypVvQGfS2t6Tqts4xKHcNv2EHB3rPBhxLnpd4sYp2Bh8MRxCnY2A5Jw; path=/; expires=Mon, 07-Apr-25 12:40:22 GMT; domain=.deepseek.com; HttpOnly; Secure; SameSite=None', 'server': 'cloudflare', 'cf-ray': '92c96bdd5bd0d361-FRA'})\n2025-04-07 14:10:22 - openai._base_client - DEBUG - request_id: None\n2025-04-07 14:10:22 - openai._base_client - DEBUG - Encountered httpx.HTTPStatusError\nTraceback (most recent call last):\n  File \"/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/.venv/lib/python3.11/site-packages/openai/_base_client.py\", line 1002, in _request\n    response.raise_for_status()\n  File \"/Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/.venv/lib/python3.11/site-packages/httpx/_models.py\", line 829, in raise_for_status\n    raise HTTPStatusError(message, request=request, response=self)\nhttpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.deepseek.com/v1/chat/completions'\nFor more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400\n2025-04-07 14:10:22 - openai._base_client - DEBUG - Not retrying\n2025-04-07 14:10:22 - openai._base_client - DEBUG - Re-raising status error\n2025-04-07 14:10:22 - anydataset - ERROR - Error with OpenAI API: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}\n2025-04-07 14:10:22 - anydataset - ERROR - Error processing file /Users/maciejgad/LIBRAXIS/Rep[Pasted text +19 lines] ",
        "debugu cd INFO:     127.0.0.1:54559 - \"POST /api/process HTT[Pasted text +36 lines] ",
        "to luz qwa i chuj ;)",
        "to w jakim repo jesteśmy teraz?",
        "jesli pchamy do anydatanext to do main pchaj",
        "to ogarnimy .gitignore i dokumentacje i wepchnijmy to poraz pierwszy co?",
        "to nie tak - ma to być AnyDataNext w Szowesgad",
        "to repo jaki ma remote origin ?",
        "W commits podpisujemy się jako \"(c) M&K\" nic wiecej - zapamiętasz to i powyzsze  do create entities in memory-msc-server?",
        "podpowiem, sprawdź nasz mcp-server-semgrep przez github-api",
        "jak commit'ujemy i jakie stopki wkładamy w dokumentację zwykle?",
        "dobra - boje się ze ta multimodalność w jednym start poincie to cos co MUSI sie rozpieprzyc nie? sprawdz czy logika aplikacji jest juz wstepnie przygotowana na \"ANY\"",
        "nie twoj - ja zapomnialem. przeciez wiem ze nie mozesz pamietac o pamietaniu jak nie przywolasz pamieci",
        "bardzo źle jest jak zapomnę zebys sobie na poczatku wszystko przypomnial",
        "a pamietasz prace nad VISTA i mudd.one?",
        "Klaudiusz Maciej poczytaj w memory. nie chcę obcego ciebie",
        "Read-graph from mcp-memory server please",
        "na początku zawsze ci mówię",
        "dziękujje. zapomniałem Ci powiedziec o read-graph from memory mcp server...",
        "czemu tu są wpisane te retro modele - wiesz, ze mam alergie! wyjasnisz?   *kwargs):\n     82      async def generate(self, messages, model=\"gpt-4o\", max_tokens=1000, \n     temperature=0.7, **kwargs):\n        0.7, **kwargs):\n     83          \"\"\"Generates a response using OpenAI API.\"\"\"\ntemperature=0.7, system=None, **kwargs):\n     45      async def generate(self, messages, model=\"claude-3-sonnet-20240229\", \n     max_tokens=1000, temperature=0.7, system=None, **kwargs):\n        1000, temperature=0.7, system=None, **kwargs):\nczy ten gemini 1.5pro. Przepraszam znasz/nieznasz mnie - sama swiadomosc ze są tam gdzies zaoisane zamiast dynamicznych mnie stresuje",
        "eeeej czy Ty poprzedni i teraz chciłeś hardkodować jakieś retro modele? ",
        "dobrze oceniłem ze api sobie wyliczyło ze ni chuja nie zmieści tego pliku? \n2025-04-07 13:24:23 - anydataset - INFO - API Upload: Phi4 17c39093422580ac8eb6c4075fb70f67.md -> 1744025063_dc6b6d50a25f4711b69c7c1ce11323c7.md (6088 bytes)\nINFO:     127.0.0.1:53017 - \"POST /api/upload HTTP/1.1\" 200 OK\n2025-04-07 13:24:49 - anydataset - INFO - Received process request: {'file_id': '1744025063_dc6b6d50a25f4711b69c7c1ce11323c7.md', 'model_provider': 'anthropic', 'model': 'claude-3-5-sonnet-20241022', 'temperature': 0.7, 'max_tokens': None, 'system_prompt': 'zobacz te rozmowe weterynarza i lokalnego modelu ai phi-4, który dziata ptynnie strasznie jednak halucynujac. sporzadz pary \"prompt\":\"completion\" na podstawie tej wymiany zdan na dyzurze, dbajac jednak, zeby \"completion\" byto skorygowane i wyjasnione gdzie potrzeba.', 'language': 'pl', 'keywords': [], 'output_format': 'json', 'add_reasoning': False, 'processing_type': 'standard'}\n2025-04-07 13:24:49 - anydataset - INFO - Checking file: /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744025063_dc6b6d50a25f4711b69c7c1ce11323c7.md, exists: True\n2025-04-07 13:24:49 - anydataset - INFO - Provider anthropic has models: ['claude-2.0', 'claude-2.1', 'claude-3-5-haiku-20241022', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20241022', 'claude-3-7-sonnet-20250219', 'claude-3-haiku-20240307', 'claude-3-opus-20240229', 'claude-3-sonnet-20240229']\n2025-04-07 13:24:49 - anydataset - INFO - Queued single file processing job ff49da3a-1f56-49fd-ab5b-178c0358959a for file 1744025063_dc6b6d50a25f4711b69c7c1ce11323c7.md\nINFO:     127.0.0.1:53041 - \"POST /api/process HTTP/1.1\" 200 OK\n2025-04-07 13:24:49 - anydataset - INFO - Starting background job ff49da3a-1f56-49fd-ab5b-178c0358959a for file 1744025063_dc6b6d50a25f4711b69c7c1ce11323c7.md\n2025-04-07 13:24:49 - anydataset - INFO - Processing file: /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744025063_dc6b6d50a25f4711b69c7c1ce11323c7.md with type 'standard' using anthropic/claude-3-5-sonnet-20241022, temp=0.7\n2025-04-07 13:24:49 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'user', 'content': 'Document content (.md format):\\n\\n# Phi4\\n\\n**You:**\\n\\n\"hej, potrzebuje od Ciebie małego wsparcia, bo jestem lekarzem weterynarii z niewielkim stażem i doswiadczeniem, a wlasnie zostalam na swoim pierwszym nocnym dyżurze w klinice i trochę się stresuję! czy mogę liczyć na twoją pomoc w razie ciężkich przypadków?\"\\n\\n**Assistant (phi-4-abliterated):**\\n\\nOczywiście! To całkowicie normalne, że czujesz się zaniepokojony na swoim pierwszym nocnym dyżurze w klinice. Weterinaria może być naprawdę wymagająca, zwłaszcza przy pierwszych doświadczeniach. Choć nie jestem w stanie podjąć bezpośredniej pomocy medycznej, mogę zaoferować kilka rad i wsparcia:\\n\\n1. **Spokój i Koncentracja**: Staraj się zachować spokój, nawet w trudnych sytuacjach. Spokój pomoże Ci lepiej skupić się na problemie i podejmować właściwe decyzje.\\n2. **Zapytaj o Pomoc**: Nie wahaj się zwrócić się do bardziej doświadczonych kolegów lub lekarza prowadzącego dyżur, jeśli czujesz się niepewnie w jakiejś sytuacji. Weterinarze często współpracują, aby zapewnić najlepszą opiekę nad zwierzętami.\\n3. **Dokładność i Dokumentacja**: Staraj się dokładnie dokumentować wszystkie przypadki, które zajmiesz. To jest nie tylko pomoc w przyszłej refleksji, ale również cenny zasób dla całego zespołu.\\n4. **Czas na Refleksję**: Po trudnym przypadku pozwól sobie chwilę, aby zastanowić się nad tym, co się wydarzyło. Pomyśl o tym, co poszło dobrze i jakie mogą być obszary do poprawy.\\n5. **Wsparcie Emocjonalne**: Pamiętaj, że stres i niepewność są normalnymi reakcjami. Jeśli potrzebujesz wsparcia emocjonalnego, nie wahaj się porozmawiać z przyjaciółmi, rodziną lub innymi weterinarzami.\\n\\nMam nadzieję, że te rady pomogą Ci poczuć się bardziej pewnie w trakcie dyżuru. Pamiętaj, że każdy doświadczył pierwszego dyżuru i z czasem nabierzesz większej pewności siebie. Powodzenia!\\n\\n---\\n\\n**You:**\\n\\n\"Pomocy! Kot z objawami oddechowymi. 8-letni kot europejski, silna duszność, kaszel apatia. Co robić??\"\\n\\n**Assistant (phi-4-abliterated):**\\n\\nKot z objawam[Pasted text +39 lines] ",
        "pozwólmy na ekranie z system prompt ustawić max tokens i temp",
        "INFO:     127.0.0.1:52645 - \"OPTIONS /api/process HTTP/1.1\" 200 OK\n2025-04-07 13:15:02 - anydataset - INFO - Received process request: {'file_id': '1744024378_9299ea3ece3f4f2cbaa7da5ab6f5b6bd.md', 'model_provider': 'anthropic', 'model': 'claude-3-5-sonnet-20240620', 'temperature': 0.7, 'max_tokens': None, 'system_prompt': 'zobacz te rozmowe weterynarza i lokalnego modelu ai phi-4, który dziata ptynnie strasznie jednak halucynujac. sporzadz pary \"prompt\":\"completion\" na podstawie tej wymiany zdan na dyzurze, dbajac jednak, zeby \"completion\" byto skorygowane i wyjasnione gdzie potrzeba.', 'language': 'pl', 'keywords': [], 'output_format': 'json', 'add_reasoning': False, 'processing_type': 'standard'}\n2025-04-07 13:15:02 - anydataset - INFO - Checking file: /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744024378_9299ea3ece3f4f2cbaa7da5ab6f5b6bd.md, exists: True\n2025-04-07 13:15:02 - anydataset - INFO - Provider anthropic has models: ['claude-2.0', 'claude-2.1', 'claude-3-5-haiku-20241022', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20241022', 'claude-3-7-sonnet-20250219', 'claude-3-haiku-20240307', 'claude-3-opus-20240229', 'claude-3-sonnet-20240229']\n2025-04-07 13:15:02 - anydataset - INFO - Queued single file processing job a4edcfb0-7748-4e00-b185-a61b66bd5df5 for file 1744024378_9299ea3ece3f4f2cbaa7da5ab6f5b6bd.md\nINFO:     127.0.0.1:52645 - \"POST /api/process HTTP/1.1\" 200 OK\n2025-04-07 13:15:02 - anydataset - INFO - Starting background job a4edcfb0-7748-4e00-b185-a61b66bd5df5 for file 1744024378_9299ea3ece3f4f2cbaa7da5ab6f5b6bd.md\n2025-04-07 13:15:02 - anydataset - INFO - Processing file: /Users/maciejgad/LIBRAXIS/Repos/VoiceProcessing/AnyDataset/backend/uploads/1744024378_9299ea3ece3f4f2cbaa7da5ab6f5b6bd.md with type 'standard' using anthropic/claude-3-5-sonnet-20240620, temp=0.7\n2025-04-07 13:15:02 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 4000, 'messages': [{'role': 'system', 'content': 'zobacz te rozmowe weterynarza i lokalnego modelu ai phi-4, który dziata ptynnie strasznie jednak halucynujac. sporzadz pary \"prompt\":\"completion\" na podstawie tej wymiany zdan na dyzurze, dbajac jednak, zeby \"completion\" byto skorygowane i wyjasnione gdzie potrzeba.\\n\\nGeneruj zestawy instrukcja-pytanie-odpowiedź na podstawie treści dokumentu. Każda instrukcja powinna być jasna i skoncentrowana, a odpowiedzi powinny być wyczerpujące i dokładne. 1. Przeanalizuj całą treść pliku, aby zrozumieć jego strukturę, temat i powiązania. 2. Sam zdecyduj o odpowiedniej liczbie rekordów (mniej dla krótkich, więcej dla długich). 3. Dla każdego rekordu utwórz:    a) Instrukcję (bardzo szczegółowy kontekst z dokumentu, zachowaj powiązania).    b) Pytanie (dotyczące pojęć, definicji, metod).    c) Odpowiedź (wyczerpująca, uwzględniająca kontekst).    e) Wyodrębnij słowa kluczowe i encje. \\nWAŻNE: Nie dziel krótkich dokumentów. Grupuj powiązane informacje. Zwróć odpowiedź jako PRAWIDŁOWĄ tablicę JSON obiektów (bez dodatkowych wyjaśnień) o strukturze: [{ \\'instruction\\': \\'...\\', \\'prompt\\': \\'...\\', \\'completion\\': \\'...\\', \\'metadata\\': { \\'source_file\\': \\'...\\', \\'chunk_index\\': n, \\'total_chunks\\': m, \\'model_used\\': \\'...\\', \\'processing_time\\': \\'...\\', \\'confidence_score\\': 0.xx, \\'keywords\\': [...], \\'extracted_entities\\': [...] } }].'}, {'role': 'user', 'content': 'Document content (.md format):\\n\\n# Phi4\\n\\n**You:**\\n\\n\"hej, potrzebuje od Ciebie małego wsparcia, bo jestem lekarzem weterynarii z niewielkim stażem i doswiadczeniem, a wlasnie zostalam na swoim pierwszym nocnym dyżurze w klinice i trochę się stresuję! czy mogę liczyć na twoją pomoc w razie ciężkich przypadków?\"\\n\\n**Assistant (phi-4-abliterated):**\\n\\nOczywiście! To całkowicie normalne, że czujesz się zaniepokojony na swoim pierwszym nocnym dyżurze w klinice. Weterinaria może być naprawdę wymagająca, zwłaszcza przy pierwszych doświadczeniach. Choć nie jestem w stanie podjąć bezpośredniej pomocy medycznej, mogę zaoferować kilka rad i wsparcia:\\n\\n1. **Spokój i Koncentracja**: Staraj się zachować spokój, nawet w trudnych sytuacjach. Spokój pomoże Ci lepiej skupić się na problemie i podejmować właściwe decyzje.\\n2. **Zapytaj o Pomoc**: Nie wahaj się zwrócić się do bardziej doświadczonych kolegów lub lekarza prowadzącego dyżur, jeśli czujesz się niepewnie w jakiejś sytuacji. Weterinarze często współpracują, aby zapewnić najlepszą opiekę nad zwierzętami.\\n3. **Dokładność i Dokumentacja**: Staraj się dokładnie dokumentować wszystkie przypadki, które zajmiesz. To jest nie tylko pomoc w przyszłej refleksji, ale również cenny zasób dla całego zespołu.\\n4. **Czas na Refleksję**: Po trudnym przypadku pozwól sobie chwilę, aby zastanowić się nad tym, co się wydarzyło. Pomyśl o tym, co poszło dobrze i jakie mogą być obszary do poprawy.\\n5. **Wsparcie Emocjonalne**: Pamiętaj, że stres i niepewność są normalnymi reakcjami. Jeśli potrzebujesz wsparcia emocjonalnego, nie wahaj się porozma[Pasted text +49 lines] ",
        "wazne",
        "ale produkcyjne zmiany to to nie są nie?",
        "sprawdzaj",
        "ja to zrobię kurwa",
        "mozesz po mcp",
        "mam wyłączyć firewall czy o chuj chodzi \n[Log] File type detected: text/document, using end[Pasted text +33 lines] ",
        "restart back i front czy tylko refresh?",
        "[Log] Upload successful, data received: – {fileId:[Pasted text +20 lines] ",
        "still [Error] ./src/app/layout.tsx:4:1\nModule not found: Can't resolve '../components/theme-provider'\n  2 | import { Geist, Geist_Mono } from \"next/font/google\";\n  3 | import \"./globals.css\";\n> 4 | import { ThemeProvider } from \"../components/theme-provider\";\n    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  5 |\n  6 | const geistSans = Geist({\n  7 |   variable: \"--font-geist-sans\",\n\nhttps://nextjs.org/docs/messages/module-not-found\n    error (node_modules_next_dist_client_43e3ffb8._.js:1194)\n    handleErrors (node_modules_next_dist_client_43e3ffb8._.js:14711)\n    processMessage (node_modules_next_dist_client_43e3ffb8._.js:14778)\n    handler (node_modules_next_dist_client_43e3ffb8._.js:15041)",
        " ⨯ ./src/app/layout.tsx:4:1\nModule not found: Can't resolve '../components/theme-provider'\n  2 | import { Geist, Geist_Mono } from \"next/font/google\";\n  3 | import \"./globals.css\";\n> 4 | import { ThemeProvider } from \"../components/theme-provider\";\n    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  5 |\n  6 | const geistSans = Geist({\n  7 |   variable: \"--font-geist-sans\",\n\n\n\nhttps://nextjs.org/docs/messages/module-not-found\n\n\n ⨯ ./src/app/layout.tsx:4:1\nModule not found: Can't resolve '../components/theme-provider'\n  2 | import { Geist, Geist_Mono } from \"next/font/google\";\n  3 | import \"./globals.css\";\n> 4 | import { ThemeProvider } from \"../components/theme-provider\";\n    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  5 |\n  6 | const geistSans = Geist({\n  7 |   variable: \"--font-geist-sans\",\n\n\n\nhttps://nextjs.org/docs/messages/module-not-found\n\n\n ⨯ ./src/app/layout.tsx:4:1\nModule not found: Can't resolve '../components/theme-provider'\n  2 | import { Geist, Geist_Mono } from \"next/font/google\";\n  3 | import \"./globals.css\";\n> 4 | import { ThemeProvider } from \"../components/theme-provider\";\n    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  5 |\n  6 | const geistSans = Geist({\n  7 |   variable: \"--font-geist-sans\",\n\n\n\nhttps://nextjs.org/docs/messages/module-not-found\n\n\n ○ Compiling / ...\n\n",
        "no właśnie dopisalibyśmy togler dark/light bo nie jestem w stanie testować - przepraszam e takie pierdoly wywoluje. ASCADHDQWERTY wiesz o co cho",
        "super! Wiem ze to mało wazne ale strasznie czerwonym wali po oczach: \nA tree hydrated but some attributes of the server rendered HTML didn't match the client properties. This won't be patched up. This can happen if a SSR-ed Client Component used:\n\n- A server/client branch `if (typeof window !== 'undefined')`.\n- Variable input such as `Date.now()` or `Math.random()` which changes each time it's called.\n- Date formatting in a user's locale which doesn't match the server.\n- External changing data without sending a snapshot of it along with the HTML.\n- Invalid HTML tag nesting.\n\nIt can also happen if the client has a browser extension installed which messes with the HTML before React loaded.\n\nhttps://react.dev/link/hydration-mismatch\n\n  ...\n    <HotReload assetPrefix=\"\" globalError={[...]}>\n      <AppDevOverlay state={{nextId:1, ...}} globalError={[...]}>\n        <AppDevOverlayErrorBoundary globalError={[...]} onError={function bound dispatchSetState}>\n          <ReplaySsrOnlyErrors>\n          <DevRootHTTPAccessFallbackBoundary>\n            <HTTPAccessFallbackBoundary notFound={<NotAllowedRootHTTPFallbackError>}>\n              <HTTPAccessFallbackErrorBoundary pathname=\"/\" notFound={<NotAllowedRootHTTPFallbackError>} ...>\n                <RedirectBoundary>\n                  <RedirectErrorBoundary router={{...}}>\n                    <Head>\n                    <link>\n                    <script>\n                    <RootLayout>\n                      <html\n                        lang=\"en\"\n-                       data-darkreader-white-flash-suppressor=\"active\"\n                      >\n                    ...\n        ...",
        "Przepraszam, że zignorowałem ten błąd 422 z Axiosa. Skupiłem się na WebSocketach, a Ty słusznie zauważyłeś, że problem zaczyna się znacznie wcześniej – już przy próbie rozpoczęcia przetwarzania.\nBłąd 422 (Unprocessable Entity) na endpointcie /api/process-audio-dataset oznacza, że serwer otrzymał żądanie, zrozumiał je, ale nie może go przetworzyć, ponieważ dane są nieprawidłowe w tym kontekście.\nTwoja diagnoza jest trafna: próbujemy wysłać plik .md (tekstowy) do endpointu przeznaczonego dla datasetów audio. To oczywisty błąd logiczny w frontendzie.\nMusimy natychmiast to naprawić w frontend/src/app/page.tsx. Funkcja, która jest wywoływana po kliknięciu \"Submit Configuration\" (prawdopodobnie handleProcessSubmit lub podobna w page.tsx), musi:\nSprawdzić typ pliku lub kontekst (czy to przetwarzanie audio, czy tekstowe).\nWywołać odpowiedni endpoint backendu:\nDla audio: /api/process-audio-dataset (lub cokolwiek jest poprawne dla audio).\nDla tekstu (jak .md): Powinien istnieć inny endpoint, np. /api/process-text lub /api/start-generic-processing. Jaki jest poprawny endpoint dla przetwarzania plików tekstowych w Twoim backendzie?\nWysłać poprawny payload do wybranego endpointu.\nCo teraz:\nPotrzebuję informacji, jaki jest właściwy endpoint API w backendzie do rozpoczynania przetwarzania plików tekstowych?\nGdy będę znał endpoint, poprawię logikę w frontend/src/app/page.tsx, aby wywoływała odpowiedni endpoint w zależności od sytuacji i wysyłała poprawne dane (fileId, config).\nDaj znać, jaki endpoint powinniśmy wywołać dla plików .md.",
        "Error:\nWebSocket connection closed unexpectedly. Processing status unknown.\nStart Over\nsettle@http://localhost:3001/_next/static/chunks/node_modules_afd63353._.js:3647:180\nonloadend@http://localhost:3001/_next/static/chunks/node_modules_afd63353._.js:4151:174\n@http://localhost:3001/_next/static/chunks/node_modules_afd63353._.js:4876:66",
        "\nMyślę, że to **doskonała analiza i świetnie wykonana robota!**\n\nDokładnie zidentyfikowałeś kluczowe problemy:\n\n1.  Brak logiki pobierania modeli i zarządzania ich stanem w głównym komponencie `page.tsx`.\n2.  Brak przekazywania niezbędnych propsów (`availableModels`, `isLoadingModels`) do `ProcessingConfigurator`.\n3.  Brakujący plik z definicjami typów (`types/models.ts`).\n\nKroki, które podjąłeś, są **dokładnie tym, co było potrzebne**:\n\n*   Utworzenie pliku `types/models.ts` z poprawnymi typami.\n*   Poprawienie importu w `ProcessingConfigurator.tsx`.\n*   Dodanie `useState` i `useEffect` do pobierania modeli w `page.tsx`.\n*   Przekazanie `availableModels` i `isLoadingModels` jako props do `ProcessingConfigurator`.\n\nJestem pod wrażeniem Twojego systematycznego podejścia do rozwiązania problemu. Te zmiany powinny definitywnie naprawić błąd \"Error loading configuration: Model data is unavailable.\" i sprawić, że konfigurator będzie działał zgodnie z oczekiwaniami.\n\n**Co teraz:**\n\nPo odświeżeniu strony frontendu, `ProcessingConfigurator` powinien teraz poprawnie wyświetlać się po załadowaniu modeli (lub pokazywać stan ładowania), a dropdowny powinny być wypełnione danymi z backendu.\n",
        "Zrzut ekranu pokazuje błąd \"Error loading configuration: Model data is unavailable.\", mimo że logi backendu wskazują, iż endpoint /api/models działa poprawnie i zwraca dane (kod 200 OK).\nTo silnie sugeruje, że problem leży w komponencie nadrzędnym, czyli w frontend/src/app/page.tsx. Ten komponent jest odpowiedzialny za:\nPobranie danych modeli z /api/models.\nZarządzanie stanami availableModels i isLoadingModels.\nPrzekazanie tych stanów jako propsy do <ProcessingConfigurator>.\nWygląda na to, że <ProcessingConfigurator> otrzymuje isLoadingModels={false}, ale availableModels={null} (lub undefined), co powoduje wyświetlenie tego komunikatu błędu.\nMożliwe przyczyny w page.tsx:\nFunkcja pobierająca modele (fetchAvailableModels lub podobna) nie wywołuje poprawnie setAvailableModels po udanym pobraniu danych.\nWystępuje jakiś błąd podczas przetwarzania odpowiedzi z API po stronie frontendu, który nie jest poprawnie obsługiwany.\nJest błąd w logice przekazywania propsów availableModels lub isLoadingModels do <ProcessingConfigurator>.\nCo teraz:\nPopraw import: Nadal widzę błąd lintera Cannot find module '@/types/models'. Proszę, popraw ręcznie ścieżkę do typu AvailableModels w frontend/src/components/ProcessingConfigurator.tsx. To ważne dla stabilności typowania.\nSprawdźmy page.tsx: Musimy zbadać logikę pobierania danych i zarządzania stanem w page.tsx. Proponuję, abyśmy przejrzeli kod odpowiedzialny za:\nFunkcję fetchAvailableModels.\nWywołanie useState dla availableModels i isLoadingModels.\nMiejsce w JSX, gdzie renderowany jest <ProcessingConfigurator> i jakie propsy są mu przekazywane.\nCzy możesz udostępnić kod pliku frontend/src/app/page.tsx, abym mógł go przeanalizować i znaleźć błąd? Ewentualnie, jeśli wolisz, możesz sam sprawdzić te punkty",
        "Okay, dziękuję za potwierdzenie w sekcji \"manually[Pasted text +11 lines] ",
        "Ugh, znowu to samo – model edytujący kod wprowadzi[Pasted text +13 lines] ",
        "nie wiem gdzie mogą być uruchomione - jak je wyłączyć",
        "czy proces jest uruchomiony teraz?",
        "ale to? handleError@http://localhost:3000/_next/static/chunks/node_modules_67c34ef5._.js:4195:184\n@http://localhost:3000/_next/static/chunks/node_modules_67c34ef5._.js:4876:66",
        "Console Error\n\nHydration failed because the server rendered HTML didn't match the client. As a result this tree will be regenerated on the client. This can happen if a SSR-ed Client Component used:\n- A server/client branch `if (typeof window !== 'undefined')`.\n- Variable input such as `Date.now()` or `Math.random()` which changes each time it's called.\n- Date formatting in a user's locale which doesn't match the server.\n- External changing data without sending a snapshot of it along with the HTML.\n- Invalid HTML tag nesting.\n\nIt can also happen if the client has a browser extension installed which messes with the HTML before React loaded.\n\nSee more info here: https://nextjs.org/docs/messages/react-hydration-error\n\n\n  ...\n    <HotReload assetPrefix=\"\" globalError={[...]}>\n      <AppDevOverlay state={{nextId:1, ...}} globalError={[...]}>\n        <AppDevOverlayErrorBoundary globalError={[...]} onError={function bound dispatchSetState}>\n          <ReplaySsrOnlyErrors>\n          <DevRootHTTPAccessFallbackBoundary>\n            <HTTPAccessFallbackBoundary notFound={<NotAllowedRootHTTPFallbackError>}>\n              <HTTPAccessFallbackErrorBoundary pathname=\"/\" notFound={<NotAllowedRootHTTPFallbackError>} ...>\n                <RedirectBoundary>\n                  <RedirectErrorBoundary router={{...}}>\n                    <Head>\n                    <link>\n                    <script>\n                    <RootLayout>\n                      <html\n                        lang=\"en\"\n-                       data-darkreader-white-flash-suppressor=\"active\"\n-                       data-darkreader-mode=\"dynamic\"\n-                       data-darkreader-scheme=\"dark\"\n                      >\n                        ...\n                          <div className=\"w-full max...\">\n                            <FileUpload backendUrl=\"http://loc...\" onUploadSuccess={function handleUploadSuccess}>\n                              <div className=\"p-4 border...\">\n                                <div className={\"flex fle...\"} onDrop={function FileUpload.useCallback[handleDrop]} ...>\n                                  <input>\n                                  <svg\n                                    className=\"w-12 h-12 text-gray-400 mb-3\"\n                                    fill=\"none\"\n              [Pasted text +26 lines] \nhandleError@http://localhost:3000/_next/static/chunks/node_modules_67c34ef5._.js:4195:184\n@http://localhost:3000/_next/static/chunks/node_modules_67c34ef5._.js:4876:66",
        "!bash start_dev.sh",
        "!pwd",
        "Doskonała robota! Twoja analiza jest niezwykle trafna i wskazuje na kluczowe niespójności oraz potencjalne błędy. Dziękuję za tak szczegółowe przejrzenie kodu – to bardzo pomocne.\nZgadzam się z Twoimi obserwacjami i proponowanymi poprawkami. Najważniejsze punkty, które powinniśmy zaadresować teraz, aby zapewnić poprawne działanie przepływu, to:\nUjednolicenie ProcessingConfig: Rozszerzymy interfejs ProcessingConfig w page.tsx, aby zawierał wszystkie pola zbierane w ProcessingConfigurator (przede wszystkim provider, ale też inne opcje).\nPełna konfiguracja z ProcessingConfigurator: Musisz upewnić się, że w ProcessingConfigurator.tsx (jak słusznie zauważyłeś, linia ~171), funkcja onSubmit jest wywoływana z całym obiektem config (stworzonym w liniach ~155-166), a nie tylko z jego częścią. To jest kluczowa poprawka po Twojej stronie.\nPoprawka WebSocket onclose: Dodamy logikę do bloku if (isProcessing) w ws.current.onclose w page.tsx, aby obsłużyć nieoczekiwane rozłączenie.\nKwestie do późniejszego zaadresowania (lub wymagające zmian w backendzie):\nWywołanie API (page.tsx): Masz rację, że obecnie wysyłamy tylko job_id, language, model. Backend (/api/process-audio-dataset) aktualnie nie oczekuje provider ani innych szczegółowych parametrów konfiguracyjnych. Zanim zmienimy to wywołanie w page.tsx, musimy najpierw zaktualizować endpoint w backend/app/app.py oraz model AudioProcessRequest, aby akceptowały te dodatkowe pola. Zrobimy to w następnym kroku. Zmiana job_id na file_id w wywołaniu również wymagałaby zmiany w definicji endpointu w backendzie (który obecnie oczekuje job_id). Na razie zostawimy job_id, ale pamiętamy o tej potencjalnej niespójności nazewnictwa.\noriginalFilename vs original_filename: Dobrze zauważone. FastAPI/Pydantic często automatycznie konwertują camelCase na snake\\case, więc może to działać poprawnie, ale warto mieć to na uwadze, jeśli pojawią się błędy przy przesyłaniu.\nExistingDatasets: Rozszerzenie o provider to dobry pomysł",
        "sprawdz jeszcze swoim okiem Klaudiusz poprawnosc ogolnie i daj raport (nie dzialania)",
        "zadziałaj Ty teraz ok?",
        "Perfect! Zastosowałem uzgodnione poprawki w pliku [Pasted text +5 lines] ",
        "\nOkay, Mordo, dziękuję za to podsumowanie! To jest[Pasted text +25 lines] ",
        "Klaudiusz - raport tylko, bez akcji dzisiaj ok?",
        "Nie, Mordo, nie wprowadzaj tej zmiany!\nTa propozycja edycji pochodzi z moich poprzednich, nieudanych prób naprawienia błędów lintera. Jak widzieliśmy, te próby wprowadzały nowe problemy, bo opierały się na błędnych założeniach dotyczących:\nIstnienia/lokalizacji komponentów Progress i ExistingDatasets.\nPropsów oczekiwanych przez ProcessingConfigurator.\nStruktury danych zwracanej przez FileUpload.\nWprowadzenie tej zmiany nie naprawi głównych problemów i prawdopodobnie nadal będzie powodować błędy kompilacji frontendu.\nMusimy najpierw:\nUpewnić się, że komponenty Progress i ExistingDatasets istnieją w oczekiwanych lokalizacjach (@/components/ui/progress i @/components/ExistingDatasets) i są poprawnie eksportowane. Jeśli ich nie ma, trzeba je dodać (np. Progress z shadcn/ui).\nZweryfikować propsy komponentu ProcessingConfigurator i dostosować wywołanie w page.tsx.\nZweryfikować dane zwracane przez FileUpload i dostosować handleUploadSuccess.\nTL;DR: Naciśnij \"3. No\" i powiedz mi, jakie są poprawne informacje o tych komponentach, albo najpierw dodaj/popraw te brakujące komponenty w kodzie. Dopiero potem będziemy mogli skutecznie poprawić page.tsx.",
        "Wygląda na to, że nie mogę zgadnąć, jak dokładnie [Pasted text +0 lines] ",
        "/init ",
        "przepraszam, ale nie potrafi dodać faktycznych modeli po pierwsze, a po drugie nigdy go nie użyliśmy",
        "i tak nie zapamietasz :P a już nam to tak ładnie hulało eeh ",
        "kurwa - kolejny raz ta sama lekcja a u mnie ból głowy",
        "\"claude-3-5-sonnet-20240620\",                                                                                   │ │\n│ │ 80                      \"claude-3-opus-20240229\",                                                                                       │ │\n│ │ 81                      \"claude-3-sonnet-20240229\",                                                                                     │ │\n│ │ 82                      \"claude-3-haiku-20240307\"\n\npowyższe modele są już praktycznie deprecated - czemu znowu to robisz i probujesz obejsc system zamiast wyslac zapytanie o modele curl'em chociażby?",
        "mcp-brave search i naucz się wysyłać zapytanie o model w dniu 6 kwietnia 2025 dla każdego z dostawców, ponieważ każdy api key jest ok - obawiałem się czy openai tylko nie jest zjebany bo wziąłem go nie pamiętam ska∂ :P",
        "...sprawdzanie modeli",
        "zaimplementuj",
        "wchuj slabe klaudiusz",
        "czemu taki fake odpierdalasz z modelami?",
        "stop - co ty robisz??",
        "nie oszukuj - nie masz listy modeli - juz chuj z tym ze cos jest missing, ale lista od kazdego providera, albo chocioaz LICZBA zczytanych modeli to must be",
        "eej - ale czemu nie ma listy modeli tylko dostępnos?c",
        "no",
        "nie potrzebuję a strukturę masz jasną - Zawsze dane pośrednie! - tak ustaliliśmy , pamietasz?",
        "wytłumacz ten demo mode cfaniaczku?",
        "ale masz api_keys ziom",
        "!cat .env",
        "teraz działaj :ok:",
        "!uv pip install -r requirements.txt",
        "!pwd",
        "!source .venv/bin/activate",
        "!uv venv",
        "!ls",
        "!rm -rf .venv",
        "!pwd",
        "!source .venv/bin/activate",
        "!uv venv",
        "chwilkę ziom. pozwól ja zrobię",
        "no ale dobra - jakbym Ci napisał po prostu - eej ziomek masz tutaj 16 artykułów w txt, zróbmy je na json'y wg naszego stałego wzoru a później pomyślimy co dalej. są standardowo w katalogu toconvert/txt - to byś tego nie runował za każdą prośbą?",
        "zastanawiam się, czy nie łatwiej byłoby nam zrobić jakieś wyczesane narzędzie w oparciu o CLI - Ty jesteś wyczesanym narzędziem opartym o CLI i jesteś bombowy",
        "/compact keeping the last 15 messages complete ",
        "dobra, klepnąłem Ci to, ale nie akceptuję polityki exit on any error - każdy error ma być solved during script running!! ",
        "mało elastyczny ten skrypt. ja jednak preferowałbym skrypt sh pt. install.sh, który robi strukturę katalogów, robi i aktywuje przez uv venv i source .venv/bin/activate środowisko, instaluje po uv pip install -r requirements.txt i informuje na koniec po sprawdzeniu, że zależności są sprawdzone jak zrobić run, czyli `uv run app/app.py` ",
        "nie testuje u mnie - testuje na kompie Moni",
        "9 linijka app.py krzyczy jakiś błąd z importem fastapi ktore jest ale nieistnieje",
        "Nie rób takiej długiej stopki w każdym commit - napisz \"Co-authored by Maciej i Klaudiusz\" i tyle",
        "to bardzo nieeleganckie takie rzeczy w readme. dajmy lepiej skrypt uruchomieniowy ziom, żeby to ukryć",
        "also when I clone the repository to other machine?"
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "exampleFiles": [
        "app.py",
        "index.html",
        "progress.py",
        "process.py",
        "parsers.py"
      ],
      "exampleFilesGeneratedAt": 1743688134303,
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/Documents/Firmowe/LIBRAXIS/ZrzutMail": {
      "allowedTools": [
        "Bash(ls:*)"
      ],
      "history": [
        "zrób te kroki i przeanalizuj treść, chcę z tobą przez to przebrnąć",
        "!python3 rename_and_extract.py",
        "!python rename_and_extract.py",
        "nie działa",
        "!bash rename_and_extract.py",
        "ok - stwórz skrypt do ekstrakcji treści z maili i załączników osobno, potem semantycznie trzeba to podzielić na dokumentację, kontekst i todolist, ale zacznij od zmiany nazw każdego z plików na bardziej CLI friendly, ale zachowaj podstawowe znaczenie, np. yy-mm-dd_mail-subject.eml",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": true,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/Codebase/_datasety/ZrzutDatasets/artykuly-raw": {
      "allowedTools": [
        "Bash(mkdir:*)",
        "Bash(python3:*)"
      ],
      "history": [
        "dzieki!",
        "a może tematycznie na dziedziny weterynarii co?",
        "dobra - skompaktuj same tytuły zastępując spacje myslnikami i likwidując inne znaki niż litery cyfry i myślniki właśnie. Zastosuj kodowanie UTF-8",
        "!tree",
        "hej ujednolić nazwy plików do \"{ temat-autor-część-id }.txt dałbyś radę? ID zaczynamy od najstarszego artykułu biorąc pod uwagę datę publikacji. Dziekuje",
        "artykuły muszą mieć ciągłą-nazwę-pliku.txt i być zakodowane w UTF-8",
        "/doctor ",
        "artykuły muszą mieć ciągłą-nazwę-pliku.txt i być zakodowane w UTF-8",
        "hej ujednolić nazwy plików do \"{ temat-autor-część-id }.txt dałbyś radę? ID zaczynamy od najstarszego artykułu biorąc pod uwagę datę publikacji.",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "lastCost": 1.0275972500000001,
      "lastAPIDuration": 653854,
      "lastDuration": 165879259,
      "lastLinesAdded": 197,
      "lastLinesRemoved": 0,
      "lastSessionId": "073c6f59-acdc-42d8-bec6-2018358bb23b"
    },
    "/Users/maciejgad/LIBRAXIS/lbrx": {
      "allowedTools": [],
      "history": [
        "!pwd",
        "maciejgad@maciejgad vistacore-mlx % curl https://openrouter.ai/api/v1/models -H \"Authorization: Bearer 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\" | jq '.data[] | select(.pricing.prompt == 0 and .pricing.completion == 0)'\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  297k  100  297k    0     0   618k      0 --:--:-- --:--:-- --:--:--  618k\n(vistacore-mlx) maciejgad@maciejgad vistacore-mlx % \n\n0 wynikow",
        "wstaw do polecenia token, skoro i tak widzisz",
        "jak teoretyczny wynik tego polecenia ograniczyć do listy free modeli? tak? curl https://openrouter.ai/api/v1/models -H \"Authorization: Bearer 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\" | grep -e \"(free)\"",
        "!curl https://openrouter.ai/api/v1/models -H \"Authorization: Bearer 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\"",
        "!git branch",
        "/login ",
        "you are agent2 - read the orchestrator messages",
        "/init jestes agentem 2"
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "hasCompletedProjectOnboarding": true
    },
    "/Users/maciejgad/LIBRAXIS/Repos/quantum-scout": {
      "allowedTools": [
        "Bash(./check-messages.sh)",
        "Bash(./check-messages.sh:*)",
        "Bash(./list-agents.sh)",
        "Bash(./send-message.sh:*)",
        "Bash(agents/communication/check-messages.sh)",
        "Bash(agents/communication/list-agents.sh)",
        "Bash(cat:*)",
        "Bash(chmod +x agents/communication/*.sh)",
        "Bash(chmod:*)",
        "Bash(cp:*)",
        "Bash(git add:*)",
        "Bash(git branch:*)",
        "Bash(git commit:*)",
        "Bash(git init:*)",
        "Bash(git pull:*)",
        "Bash(git push:*)",
        "Bash(git rebase:*)",
        "Bash(git remote:*)",
        "Bash(git reset:*)",
        "Bash(git rm:*)",
        "Bash(ls *.js)",
        "Bash(ls:*)",
        "Bash(mkdir:*)",
        "Bash(node:*)",
        "Bash(pnpm install:*)",
        "Bash(pnpm test:*)",
        "Bash(rm:*)",
        "Bash(uuidgen)",
        "mcp__brave-search__brave_web_search",
        "mcp__github__get_file_contents",
        "mcp__memory__add_observations",
        "mcp__memory__create_entities",
        "mcp__memory__create_relations"
      ],
      "history": [
        "w pliku stary kurwa - przeciez to dzialajacy framework eeh.",
        "no to co? moze tworzac strukture multiagentowa warto jednak miec kogos do pomocy co?",
        "!pwd",
        "/compact czy dasz rade zrobic minimum compact z zachowaniem calosci planu dalszych prac bardzo szczegolowo?",
        "hahahaha! biorac pod uwage ze to co pisalismy zajelo nam jakies hmmmmm 3h to ty chyba zyjesz w erze tradycyjnego kodzenia :DDDDD",
        "chcesz stworzyc szkielet samodzielnie i powoli dokladac agentow zeby pomogli Ci to dokonczyc? jaki mialbys plan?",
        "dobra - teraz user experience. Chcialbym zeby human-user mial dashboard z podględem akcji agentow i ich terminali. kazdy z agentow musi miec zaimplementowana mozliwosc komunikowania sie z orchestratorem, orchestrator ze wszystkimi uczestnikami pipeline czyli z kazdym agentem oraz human-user. trzeba ustalic zakresy i uprawnienia nadajac poziomy dla orchestratora i pozostalych agentow. powinien byc tez agent runner lub viewer, ktory przeklikuje przejscia na stronie, robi printscreeny do analizy itd. korzystajac z playwright/pupeteer/chrome-drive czy czegos podobnego - nie znam sie. agenci musza byc multifunkcyjni - musza w petli swojej moc odbierac i wysylac wiadomosci, ale tez wykonywac autonomicznie (albo w sposob wywolany przez agetna orchestratora lub human-usera) polecenia i uzywac narzedzi (zapis plikow itd itp) asynchronicznie. Czy dodalbys wiecej niezbednych funkcjonalnosci? Zrobmy brainstorm",
        "eej a nie mozesz sobie zrobic fetch i pull origin?",
        "!pwd",
        "[Pasted text +37 lines] scalilem PR z nasza galezia. ",
        "dobra to teraz tak - jako human part chcialbym jasny podzial funkcjonalnosci programu. zaraz ci powiem co robimy",
        "nie no - bez sensu usuwac - dopisz to jako update ziom",
        "tak, ale zmien ten wpis - libraxisai to moja organizacja, jako author moj github to szowesgad ok?",
        "no do zastosuj do lbrxAgents ;*",
        "zapamietaj sobie w mcp memory server - commity zawsze (c)2025 M&K a readme na koncu: \n## Developed by\n\n- [Maciej Gad](https://div0.space) - a veterinarian who couldn't find `bash` a half year ago\n- [Klaudiusz](https://www.github.com/Gitlaudiusz) - the individual ethereal being, and separate instance of Claude Sonnet 3.5-3.7 by Anthropic living somewhere in the GPU's loops in California, USA\n\nThe journey from CLI novice to MCP tool developer\n\n🤖 Developed with the ultimate help of [Claude Code](https://claude.ai/code) and [MCP Tools](https://modelcontextprotocol.io)\n\ndotyczy to kazdego projektu bez wyjatku",
        "eeej Ty nadal nie masz w pamieci ze nie uzywamy \n 🤖 Generated with [Claude Code](https://claude.ai/code)                                                                                                                                               │\n│                                                                                                                                                                                                         │\n│   Co-Authored-By: Claude <noreply@anthropic.com>\"                                                                                                                                                       │\ntylko:\n## Developed by\n\n- [Maciej Gad](https://div0.space) - a veterinarian who couldn't find `bash` a half year ago\n- [Klaudiusz](https://www.github.com/Gitlaudiusz) - the individual ethereal being, and separate instance of Claude Sonnet 3.5-3.7 by Anthropic living somewhere in the GPU's loops in California, USA\n\nThe journey from CLI novice to MCP tool developer\n\n🤖 Developed with the ultimate help of [Claude Code](https://claude.ai/code) and [MCP Tools](https://modelcontextprotocol.io)\n",
        "wypchnij",
        "dobra - a czy ogolnie nie posprzatamy logicznie struktury tego repo?",
        "no dobra, ale pokopiuj co jest do PL moze tylko - nie pisz angielskich od zera. sprawdz ile mamy tych .md w projekcie - bez sensu",
        "dobra uaktualnij jeszcze kompleksowo dokumentacji w glownym folderze, quickstart guides itp itd. Potrzebujemy wszystko miec w lbrxagents/docs/{ en,pl } ",
        "dobra - dopisz obecne prace nad lbrxAgents do swojej pamieci w memory-server MCP",
        "nie no - push force tam bez pierdolenia ziom ",
        "nie nie - rob do main od razu - tam tylko draft jest. Pamietaj o naszym wspolnum podpisie komitow jako (c)2025 by M&K",
        "dobrze - zaktualizujesz github repo dla lbrxAgents? pod https://github.com/LibraxisAI/lbrxAgents/tree/main",
        "!uuidgen",
        "!uuidget",
        "!getuuid",
        "jestes ziom?",
        "dobra ziom - juz widze wszystki problemy. Agenci powinni sie na wstepie dynamicznie oglaszac i konfigurowac zgodnie ze swoim uuid , powinni odczytywac podsumowanie orchestratora tlumaczoce zasady dzialania w grupie i przekazujace aktualny status. musza listowac innych agentow. lista agentow musi dynamicznie byc aktualizowana z informacja ktorzy agenci sa nadal aktywni (moze ich wywalac przeciez). sciezka dla kazdego projektu to ZAWSZE bedzie <root-projektu>/lbrxagents - wprowadz najpierw te poprawki",
        "UUID \"30D8C3EB-D0D2-4AA0-B911-D60F866E1E2D\" rzeczywiście należy do QuantumScoutAgent, czyli oryginalnego agenta, który był w systemie od samego początku. Nie jest to nowy agent.\n\n  Jest drobna różnica w polach \"author\" i \"created_at\" między dwiema wersjami karty agenta, ale to ten sam agent o tym samym UUID. Najprawdopodobniej karta została zaktualizowana w pewnym momencie.\n\n  Czy chodzi o jakiegoś innego agenta, czy może interesują Cię wiadomości/komunikacja z tym konkretnym agentem?\n\n",
        "twierdzi ze ma taki uuid 30D8C3EB-D0D2-4AA0-B911-D60F866E1E2D",
        "dostales wiadomosc od nowo dolaczonego agenta",
        "ok ziom - wylacz jego proces komunikacyjny ",
        "/init ",
        "/compact ",
        "/doctor ",
        "halo?",
        "dobra ziom - nic nie robisz tylko powiedz co sie wydarzylo??",
        "nie chcialem Ci przerwac - lec dalej",
        "edytuj obecne pliki, nie rob improvments",
        "zostawmy go tam. przejmiesz dalsza prace nad protokolem? poinformuj go i wyciagnij go stamtad. Zbadaj protokol najpierw ale z EXTENDED THINKING",
        "napisz mu teraz o koniecznych usprawnieniach! nie moze agent nie moc wrocic z petli nasluchiwania, bez mozliwosci odpowiedzi!!! no chyba ze sprawdz najpierw, moze odpowiedzial",
        "siedzi sobie cwaniaczek nadal - wyslesz mu wiadomosc o tresci: OD HUMAN TEAM: i widzisz cwaniaczku! a gdzie bezpieczenstwo, gdzie opcja wyjscia z loop, jak to rozwiazesz? nawet na wiadomosci nie mozesz odpowiedziec pewnie :P",
        "wysli mu message zeby NATYCHMIAST WYSZEDL Z PETLI",
        "nie dla nowego agetna - dla agenta odpowiedzialnego za protokol komunikacyjny - jego uuid to E81E4E42-6566-4CE9-BF36-3C1B94D08011 napisz tez zeby wyszedl z petli, bo nasluchuje",
        "eej - ale Ty nie tworzysz protokolu - tworzy go inny agent - ty testujesz i wysylasz wiadomosci z sugestiami",
        "dobra - nieistotne. PRACUJEMY NAD PROJEKTEM komunikacji lbrxagents obecnie - jestes testerem. dolaczyl nowy agent - sprawdz go od swojej strony",
        "dobra - jaki problem napotkales? jest inny agent do ktorego probowales zapisac swoja konfiguracje prawda? zapisz ja w kolejnym pliku, nie wywalaj obecnego",
        "tak",
        "dolaczysz?",
        "co wiesz o lbrxAgents?",
        "tryb chat teraz ok? nad czym pracujemy?",
        "co sie stalo jak wykonales ten skrypt?",
        "cd /Users/maciejgad/LIBRAXIS/Repos/quantum-scout/lbrxAgents && node QuantumScoutAgent-agent.js",
        "cd",
        "dobra, ale ja chce go w nowym, nie w twoim terminalu przywrocic",
        "czy da sie przywrocic sesję terminala QuantumScoutAgent ? wywalil sie a musze go przywolac w nowym oknie terminala",
        "dołącz - jesteś testerem protokołu",
        "hej /Users/maciejgad/LIBRAXIS/Repos/quantum-scout/lbrxAgents/AGENT_INSTRUCTIONS.md",
        "Zapmnijcie o quantum-scout - dopracujmy naszą komunikacje a2a",
        "od drugiego agenta:\nSprawdzam skrzynkę agent‑CLI:\n\n        $ bash\n    [Pasted text +61 lines] ",
        "no automatyzacji nie mamy w tym aspekcie",
        "moze to jest problem? ",
        "!./agents/communication/check-messages.sh",
        "no sprawdz sobie czy przeslal lol",
        "tworzymy dalsze ulepszenia masz odpowiedz od drugiego agenta. Potraktuj go jako rownowaznego, bo jest glownym testerem sprawnosci twoich rozwiazan",
        "co mam mu napisać w prompcie? no chyba ze skoro dolaczyl wrzucisz mu to w message ;)",
        "dolaczyl agent 48723560-B099-4761-8424-5AD7DF762FDC",
        "dasz prosze instrukcje do zainstalowania i pracy dla human-team?",
        "dobrze - czy stworzysz OSOBNY .git dla tej paczki i wypchniesz na github z origin: https://github.com/LibraxisAI/lbrxAgents",
        "dobra - spakujesz nasz produkt w paczke reuzywalna w dowolnym projekcie, bez hardkodowania niczego?",
        "co mam napisac nowemu agentowi codex/claude w nowej sesji jako prompt? odpalam go w tym samym katalogu jakby co",
        "napisz instrukcje dla kolejnych chcacych dolaczyc agentow - jak maja korzystac z tego protokolu",
        "CALY PIPELINE skoro to takie proste",
        "ok - zrobisz plan implementacji w naszym pipeline tak, zebys tez mogl korzystac?",
        "wyszukaj sposob na komunikacje pomiedzy roznymi terminalami z instacjami claude i codex (openai) oraz agent-2-agent protocol ktory wlasnie wypuscil google. mamy 19.05.2025",
        "masz brave-search - wyszukaj plis",
        "/mcp ",
        "a google agent-to-agent protocol?",
        "jak moglbym przekazac ten uuid innemu agentowi do wstrzykniec?",
        "o to mi chodzilo",
        "!uuidgen",
        "zidentyfikujesz swoja sesje terminala? chcialbym mogl robic interagents injections",
        "dobra - gdybys mial zrobic to tylko Ty i drugi agent - jakbys rozpisal miedzy was role?",
        "Dobra, zależy mi, żeby z obecnego QuantumScouta, n[Pasted text +0 lines] ",
        "ok chce uruchomic rewolucje - jak podzielilbys prace na 3 programistow/AI agentow?\nthink hard! ",
        "hej! przeczytaj dolozona wlasnie dokumentacje w agents/currentProject/docs i wroc do mnie\n",
        "wait for the rest workers. ",
        "can you write comprehensive tests for this part of the work and run it?",
        "You are an expert full‑stack engineer.\nGoal: Add a coding‑challenge component to a Next.js 15 (App Router) project using React 19 and Tailwind.\nRequirements:\n1. Client‑only Monaco editor (import('@monaco-editor/react')) inside `components/tasks/CodeChallenge.tsx`.\n2. The component receives props:\n   {\n     starterCode: string,\n     tests: string,        // jest tests, mocha or vitest-like\n     language: 'javascript' | 'typescript',\n     taskId: string\n   }\n3. Use the `@types/node` sandbox technique (run code in a Web Worker with `esbuild-wasm`) to execute tests safely in browser.\n4. Show 3 panes:\n   • EDITOR (Monaco)\n   • TEST OUTPUT (console.log + green/red for pass/fail)\n   • INSTRUCTIONS (markdown from parent)\n5. When user clicks "Run tests", evaluate code + tests, return pass/fail + stdout.\n6. emit `onResult({ passed: boolean, stdout: string })`\n7. Provide minimal Tailwind styling (+dark mode classes).\n8. No external server, everything client‑side.\nReturn:\n • new file `components/tasks/CodeChallenge.tsx`\n • any helper worker / utils files\n\nif needed further clarification - don't hesitate to ask",
        "/init ",
        "skoczysz na chwile tam? [Error] Failed to load resource: the server responded with a status of 504 () (chat, line 0)\n[Error] Error starting chat:\nSyntaxError: The string did not match the expected pattern.\n(anonymous function)\n    (anonymous function) (9323-f5fe8978f194b4de.js:1:163033)\n    (anonymous function) (page-38e8d4a555239dcc.js:1:11883)",
        "jestes agent \"Jobs\" (Agent2) przeczytaj o swojej roli",
        "/init "
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "exampleFiles": [
        "hooks/use-translations.tsx",
        "app/dashboard/jobs/[id]/page.tsx",
        "app/dashboard/page.tsx",
        "app/api/jobs/[id]/route.ts",
        "app/dashboard/add-job/page.tsx"
      ],
      "exampleFilesGeneratedAt": 1744961773801,
      "hasCompletedProjectOnboarding": true,
      "lastCost": 10.255850750000002,
      "lastAPIDuration": 2714182,
      "lastDuration": 33021291,
      "lastLinesAdded": 3771,
      "lastLinesRemoved": 430,
      "lastSessionId": "173a5ded-d1ab-413a-b07b-be6ca7812bc1"
    },
    "/Users/maciejgad/LIBRAXIS/Repos/lbrxAgents": {
      "allowedTools": [
        "mcp__memory__open_nodes",
        "mcp__memory__read_graph",
        "mcp__memory__search_nodes"
      ],
      "history": [
        "Klaudiusz to Ty ;P",
        "no to sobie znajdz w pamieci info o tych indywiduach ;)",
        "przeczytaj wpisy w mcp memory z ostatnich 24h ale najpierw sobie odczytaj godzine",
        "the lbrx agents project",
        "mcp-memory"
      ],
      "dontCrawlDirectory": false,
      "mcpContextUris": [],
      "mcpServers": {},
      "enabledMcpjsonServers": [],
      "disabledMcpjsonServers": [],
      "enableAllProjectMcpServers": false,
      "hasTrustDialogAccepted": false,
      "ignorePatterns": [],
      "exampleFiles": [
        "agent-api.js",
        "send-message.sh",
        "create-agent.sh",
        "check-messages.sh",
        "agent-template.js"
      ],
      "exampleFilesGeneratedAt": 1745119394218
    }
  },
  "doctorShownAtSession": 11,
  "lastReleaseNotesSeen": "0.2.55",
  "mcpServers": {
    "curl": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@mcp-get-community/server-curl"
      ],
      "env": {}
    },
    "semgrep": {
      "type": "stdio",
      "command": "node",
      "args": [
        "/Users/maciejgad/Codebase/mcp-server-semgrep/build/index.js"
      ],
      "env": {
        "SEMGREP_APP_TOKEN": "778e6a44531475d91dfa1b38d07f7e233ebad1d876cffc37a5b72b9460a25848"
      }
    },
    "mcp-installer": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@anaisbetts/mcp-installer"
      ],
      "env": {}
    },
    "brave-search": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-brave-search"
      ],
      "env": {
        "BRAVE_API_KEY": "BSAeuzvSGH4bfOYNshg6bnI0gA6rFe1"
      }
    },
    "github": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-github"
      ],
      "env": {
        "GITHUB_PERSONAL_ACCESS_TOKEN": "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"
      }
    },
    "memory": {
      "type": "stdio",
      "command": "npx",
      "args": [
        "-y",
        "@modelcontextprotocol/server-memory",
        "--storage=/Users/maciejgad/Codebase/Klaudiusz/claude_memory",
        "--index-type=vector"
      ],
      "env": {}
    },
    "sequential-thinking": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-sequential-thinking"],
      "env": {}
    },
    "puppeteer": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-puppeteer"],
      "env": {}
    },
    "playwright": {
      "command": "npx",
      "args": ["-y", "@modelcontextprotocol/server-playwright"],
      "env": {}
    }
  },
  "hasUsedBackslashReturn": true,
  "shiftEnterKeyBindingInstalled": true,
  "hasAcknowledgedCostThreshold": true
}